<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Time Series</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Introduction to Time Series">
  <meta name="generator" content="bookdown 0.1.4 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Time Series" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://coatless.github.io/its/" />
  
  
  <meta name="github-repo" content="coatless/its" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Time Series" />
  
  
  

<meta name="author" content="James Balamuta and Stephane Guerrier">

<meta name="date" content="2016-08-16">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="autocorrelation-and-stationarity.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { extensions: ["AMSmath.js"], 
         equationNumbers: { autoNumber: "AMS" },
         Macros: {
          notimplies: "\\nRightarrow",
          mean: ["\\operatorname{mean}"],
          var: ["\\operatorname{var}"],
          tr: ["\\operatorname{tr}"],
          cov: ["\\operatorname{cov}"],
          corr: ["\\operatorname{corr}"],
          argmax: ["\\operatorname{argmax}"],
          argmin: ["\\operatorname{argmin}"],
          card: ["\\operatorname{card}"],
          diag: ["\\operatorname{diag}"],
          rank: ["\\operatorname{rank}"],
          length: ["\\operatorname{length}"]
    }
  }
});
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="styling/style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Time Series</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#a-foreword"><i class="fa fa-check"></i><b>1.1</b> A foreword</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#rendering-mathematical-formulae"><i class="fa fa-check"></i><b>1.2</b> Rendering Mathematical Formulae</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#mathematical-notation"><i class="fa fa-check"></i><b>1.3</b> Mathematical Notation</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#r-code-conventions"><i class="fa fa-check"></i><b>1.4</b> R Code Conventions</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.5</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#exploratory-data-analysis-eda-for-time-series"><i class="fa fa-check"></i><b>2.1</b> Exploratory Data Analysis (EDA) for Time Series</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#basic-time-series-models"><i class="fa fa-check"></i><b>2.2</b> Basic Time Series Models</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#white-noise-processes"><i class="fa fa-check"></i><b>2.2.1</b> White noise processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html"><i class="fa fa-check"></i><b>3</b> Autocorrelation and Stationarity</a><ul>
<li class="chapter" data-level="3.1" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#dependency"><i class="fa fa-check"></i><b>3.1</b> Dependency</a><ul>
<li class="chapter" data-level="3.1.1" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#measuring-linear-dependence"><i class="fa fa-check"></i><b>3.1.1</b> Measuring (Linear) Dependence</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#the-autocorrelation-and-autocovariance-functions"><i class="fa fa-check"></i><b>3.2</b> The Autocorrelation and Autocovariance Functions</a><ul>
<li class="chapter" data-level="3.2.1" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#definitions"><i class="fa fa-check"></i><b>3.2.1</b> Definitions</a></li>
<li class="chapter" data-level="3.2.2" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#a-fundamental-representation"><i class="fa fa-check"></i><b>3.2.2</b> A Fundamental Representation</a></li>
<li class="chapter" data-level="3.2.3" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#admissible-autocorrelation-functions"><i class="fa fa-check"></i><b>3.2.3</b> Admissible autocorrelation functions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#stationarity"><i class="fa fa-check"></i><b>3.3</b> Stationarity</a><ul>
<li class="chapter" data-level="3.3.1" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#definitions-1"><i class="fa fa-check"></i><b>3.3.1</b> Definitions</a></li>
<li class="chapter" data-level="3.3.2" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#assessing-weak-stationarity-of-time-series-models"><i class="fa fa-check"></i><b>3.3.2</b> Assessing Weak Stationarity of Time Series Models</a></li>
<li class="chapter" data-level="3.3.3" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#esimtation-of-the-mean-function"><i class="fa fa-check"></i><b>3.3.3</b> Esimtation of the Mean Function</a></li>
<li class="chapter" data-level="3.3.4" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#sample-autocovariance-and-autocorrelation-functions"><i class="fa fa-check"></i><b>3.3.4</b> Sample Autocovariance and Autocorrelation Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="autocorrelation-and-stationarity.html"><a href="autocorrelation-and-stationarity.html#joint-stationarity"><i class="fa fa-check"></i><b>3.4</b> Joint Stationarity</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-models.html"><a href="basic-models.html"><i class="fa fa-check"></i><b>4</b> Basic Models</a><ul>
<li class="chapter" data-level="4.1" data-path="basic-models.html"><a href="basic-models.html#the-backshift-operator"><i class="fa fa-check"></i><b>4.1</b> The Backshift Operator</a></li>
<li class="chapter" data-level="4.2" data-path="basic-models.html"><a href="basic-models.html#white-noise"><i class="fa fa-check"></i><b>4.2</b> White Noise</a></li>
<li class="chapter" data-level="4.3" data-path="basic-models.html"><a href="basic-models.html#moving-average-process-of-order-q-1-a.k.a-ma1"><i class="fa fa-check"></i><b>4.3</b> Moving Average Process of Order q = 1 a.k.a MA(1)</a></li>
<li class="chapter" data-level="4.4" data-path="basic-models.html"><a href="basic-models.html#drift"><i class="fa fa-check"></i><b>4.4</b> Drift</a></li>
<li class="chapter" data-level="4.5" data-path="basic-models.html"><a href="basic-models.html#random-walk"><i class="fa fa-check"></i><b>4.5</b> Random Walk</a></li>
<li class="chapter" data-level="4.6" data-path="basic-models.html"><a href="basic-models.html#random-walk-with-drift"><i class="fa fa-check"></i><b>4.6</b> Random Walk with Drift</a></li>
<li class="chapter" data-level="4.7" data-path="basic-models.html"><a href="basic-models.html#autoregressive-process-of-order-p-1-a.k.a-ar1"><i class="fa fa-check"></i><b>4.7</b> Autoregressive Process of Order p = 1 a.k.a AR(1)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="arma.html"><a href="arma.html"><i class="fa fa-check"></i><b>5</b> ARMA</a><ul>
<li class="chapter" data-level="5.1" data-path="arma.html"><a href="arma.html#definition"><i class="fa fa-check"></i><b>5.1</b> Definition</a></li>
<li class="chapter" data-level="5.2" data-path="arma.html"><a href="arma.html#ma-ar-operators"><i class="fa fa-check"></i><b>5.2</b> MA / AR Operators</a></li>
<li class="chapter" data-level="5.3" data-path="arma.html"><a href="arma.html#redundancy"><i class="fa fa-check"></i><b>5.3</b> Redundancy</a></li>
<li class="chapter" data-level="5.4" data-path="arma.html"><a href="arma.html#causal-invertible"><i class="fa fa-check"></i><b>5.4</b> Causal + Invertible</a></li>
<li class="chapter" data-level="5.5" data-path="arma.html"><a href="arma.html#estimation-of-parameters"><i class="fa fa-check"></i><b>5.5</b> Estimation of Parameters</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ar1-with-mean-mu.html"><a href="ar1-with-mean-mu.html"><i class="fa fa-check"></i><b>6</b> <span class="math inline">\(AR(1)\)</span> with mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="7" data-path="conditioning-time-x-t-x-t-1.html"><a href="conditioning-time-x-t-x-t-1.html"><i class="fa fa-check"></i><b>7</b> Conditioning time <span class="math inline">\(x_t | x_{t-1}\)</span></a></li>
<li class="chapter" data-level="8" data-path="mle-for-sigma-2-on-ar1-with-mean-mu.html"><a href="mle-for-sigma-2-on-ar1-with-mean-mu.html"><i class="fa fa-check"></i><b>8</b> MLE for <span class="math inline">\(\sigma ^2\)</span> on <span class="math inline">\(AR(1)\)</span> with mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="9" data-path="conditional-mle-on-ar1-with-mean-mu.html"><a href="conditional-mle-on-ar1-with-mean-mu.html"><i class="fa fa-check"></i><b>9</b> Conditional MLE on <span class="math inline">\(AR(1)\)</span> with mean <span class="math inline">\(\mu\)</span></a><ul>
<li class="chapter" data-level="9.1" data-path="conditional-mle-on-ar1-with-mean-mu.html"><a href="conditional-mle-on-ar1-with-mean-mu.html#method-of-moments"><i class="fa fa-check"></i><b>9.1</b> Method of Moments</a><ul>
<li class="chapter" data-level="9.1.1" data-path="conditional-mle-on-ar1-with-mean-mu.html"><a href="conditional-mle-on-ar1-with-mean-mu.html#method-of-moments---arp"><i class="fa fa-check"></i><b>9.1.1</b> Method of Moments - AR(p)</a></li>
<li class="chapter" data-level="9.1.2" data-path="conditional-mle-on-ar1-with-mean-mu.html"><a href="conditional-mle-on-ar1-with-mean-mu.html#yule-walker"><i class="fa fa-check"></i><b>9.1.2</b> Yule-Walker</a></li>
<li class="chapter" data-level="9.1.3" data-path="conditional-mle-on-ar1-with-mean-mu.html"><a href="conditional-mle-on-ar1-with-mean-mu.html#estimates"><i class="fa fa-check"></i><b>9.1.3</b> Estimates</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="conditional-mle-on-ar1-with-mean-mu.html"><a href="conditional-mle-on-ar1-with-mean-mu.html#prediction-forecast"><i class="fa fa-check"></i><b>9.2</b> Prediction (Forecast)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/coatless/its" target="blank">&copy; 2016 James Balamuta, Stephane Guerrier</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Time Series</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Introduction</h1>
<!--
> "One damned thing after another." ~ R. A. Fisher
>
-->
<blockquote>
<p><em>Prévoir consiste à projeter dans l’avenir ce qu’on a perçu dans le passé.</em> Henri Bergson</p>
</blockquote>
<!--
>
> *Hâtons-nous; le temps fuit, et nous entraîne avec soi : le moment où je parle est déjà loin de moi*. Nicolas Boileau
>
-->
<p>Generally speaking a <em>time series</em> (or stochastic process) corresponds to set of “repeated” observations of the same variable such as price of a financial asset or temperature in a given location. In terms of notation a time series is often writen as</p>
<p><span class="math display">\[\left(X_1, X_2, ..., X_T \right) \;\;\; \text{ or } \;\;\; \left(X_t\right)_{t = 1,...,T}.\]</span></p>
<p>The time index <span class="math inline">\(t\)</span> generally the set <span class="math inline">\(\mathbb{N}\)</span> (or sometimes <span class="math inline">\(\mathbb{Z}\)</span>). When <span class="math inline">\(t \in \mathbb{R}\)</span>, a time series becomes a <em>continuous-time</em> stochastic process such a Brownian motion. In this class we limit our selves to <em>discrete-time</em> processes where a variable is measured sequentially at fixed and equally spaced intervals in time. This implies that we will assume <span class="math inline">\(t\)</span> is not random (the time at which each observation is measure is know) and the time between two consequtive observation is constant.</p>
<p>Moreover, the term “time series” can, as we discussed, denote a sample or a set of observations but also a probability model for that sample. For example, on of the simplest probability model used in time series analysis is called a <em>white noise</em> process and is defined as <span class="math display">\[W_t \mathop \sim \limits^{iid} N(0, \sigma^2).\]</span> This statement simply means that <span class="math inline">\((X_t)\)</span> is normally distribtued and independent over time. This model is quite unintersting but as we will very usefull to construct other (more interesting) models. Unlike white noise process, time series are typically <em>not</em> independent over time. Suppose that the temperature in Champaign is unusually low, then it is reasonable to assume that tomorrow’s temperature will also be low. Such behaviour suggest a dependent over time. The time series methods we will discuss in this class consists parametric models used to characterize (or at least approximate) the joint distribution of <span class="math inline">\((X_t)\)</span>. Often, time series models can be decomposed in what we called a <em>signal</em>, say <span class="math inline">\((Y_t)\)</span> and a <em>noise</em>, say <span class="math inline">\((W_t)\)</span>, leading to the model <span class="math display">\[X_t = Y_t + W_t.\]</span> Typically, we have <span class="math inline">\(E[Y_t] \neq 0\)</span> while <span class="math inline">\(E[W_t] = 0\)</span> (although we may have <span class="math inline">\(E[W_t | W_{t-1}, ..., W_1] \neq 0\)</span>). Such models impose some parametric structure which represent a convenient and flexible way of studying time series and evalute to which extent <em>future</em> value of the series can be forecasted. As we will see, predicting future values is one of the main aspects of time series analysis. However, making predictions is often a daunting taks or as famously stated by Nils Bohr:</p>
<blockquote>
<p>“<em>Prediction is very difficult, especially about the future.</em>”</p>
</blockquote>
<p>There are plenty of examples predictions which releved to be completely erroneous. For example, Irving Fisher, Professor of Economics at Yale University, famously predicted three days before the 1929 crash:</p>
<blockquote>
<p>“<em>Stock prices have reached what looks like a permanently high plateau</em>”.</p>
</blockquote>
<p>Another example is Thomas Watson, president of IBM, who said in 1943:</p>
<blockquote>
<p>“<em>I think there is a world market for maybe five computers.</em>”</p>
</blockquote>
<!-- Model = Pattern + Noise

In Time Series, the pattern represents the association between values observed over time (e.g. autocorrelation). 

***Since these patterns are correlated in time, methods that assume independence are unable to be used.***





In essence, we seek to be able to predict, classify, and associate observed data with a theoretical backend.

 ## Objective of Time Series

1. View a set of observations made sequentially in "time."
    * "One damned thing after another." ~ R. A. Fisher
2. Find a suitable model to describe an observed process 
    * "All models are wrong, but some are useful" ~ George Box
3. Forecast future observations 
    * "Prediction is very difficult, especially if it's about the future." ~ Niels Bohr 


## What is a Time Series and can I eat it?

The definition of ***Time Series (TS)*** is as follows: 

A ***Time Series*** is a stochastic process, a sequence of random variables (RV) defined on a common probability space denoted as $\left(X_t\right)_{t=1, \ldots, T}$ (i.e. $X_1, X_2, \ldots, X_T$).

-->
<p>Examples of Time Series:</p>
<pre><code>## Loading required package: xts</code></pre>
<p><img src="its_files/figure-html/example_highfreq-1.png" width="672" /></p>
<ol style="list-style-type: decimal">
<li><p>Stock Data from Johnson and Johson’s Quarterly earnings…</p></li>
<li><p>Earthquake and explosion data</p></li>
</ol>
<p><img src="its_files/figure-html/example_eq-1.png" width="672" /></p>
<div id="exploratory-data-analysis-eda-for-time-series" class="section level2">
<h2><span class="header-section-number">2.1</span> Exploratory Data Analysis (EDA) for Time Series</h2>
<p>When dealing with relatively small time series (e.g. a few thousands), it is often useful to look at a graph of the original data. Such graphs can be informative to “detect” some features of a time series such as trends and the presence of outliers.</p>
<p>Indeed, a trend is typically deamed present in a time series when the data exhibit some form of long term increase or decrease or combination of increases or decreases. Such trends could be linear or non-linear and represent a important part of the “signal” of a model. Here are few examples of non-linear trends:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Seasonal trends</strong> (periodic): These are the cyclical patterns which repeat after a fixed/regular time period. This could be due to business cycles (e.g. bust/recession, recovery).</p></li>
<li><p><strong>Non-seasonal trends</strong> (periodic): These patterns cannot be associated to seasonal variation and can for example to external variable. For example, impact of economic indicators on stock returns. Such trends are often hard to detect based on a graphical anaylsis of the data.</p></li>
<li><p><strong>“Other” trends</strong>: These trends have typically no regular patterns and change statistical properties of a time series over a segment of time (“window”). A typicall example of such trends corresponds to vibrations observed before, during and after an earthquake.</p></li>
</ol>
<p><strong>Example:</strong> An example of a time series is, for example, the quarterly earnings of the company Johnson and Johson. In the figure below we present these earnings between 1960 and 1980:</p>
<p><strong>JAMES: can we “gmwm” this graph? Thanks!</strong></p>
<p><img src="its_files/figure-html/example_jj-1.png" width="672" /></p>
<p>It can clearly be observed that the data present a non-linear increasing trend as well as a yearly seasonal component. In addition, on can note that the <em>variability</em> of the data seems to increase with time. As we will such observations provide some valuable guilines to select a suitable models for such data.</p>
<p><strong>Example:</strong> In the figure below we present TO COMPLETE</p>
<p><strong>JAMES: can we “gmwm” this graph? Thanks!</strong></p>
<p><img src="its_files/figure-html/example_eq-1.png" width="672" /></p>
<p><strong>ADD VISUAL DESCRIPTION</strong></p>
<p>Change in time and outliers yields interesting results. These results can be seen as:</p>
<ol style="list-style-type: decimal">
<li>Change in Means
<ul>
<li>Change in means of a TS can be related to long-term, cyclical, and short-term trends.</li>
</ul></li>
<li>Change in Variance
<ul>
<li>Change in variance can be related to change in the amplitude of the fluctuations of a TS.</li>
</ul></li>
<li>Change in State
<ul>
<li>An event which causes change in statistical properties of TS for short term and long term! Some events cause abrupt changes in statistical properties of TS. They are often associated with “explosive” nature of TS.</li>
</ul></li>
<li>Outliers
<ul>
<li>These are the “extreme” observations in the time series. May be related to data collection or change in state.</li>
</ul></li>
</ol>
</div>
<div id="basic-time-series-models" class="section level2">
<h2><span class="header-section-number">2.2</span> Basic Time Series Models</h2>
<p>In this section, we introduce some simple time series models. Before doing so we define all the information avaiable up to time <span class="math inline">\(t-1\)</span> has <span class="math inline">\(\Omega_t\)</span>, i.e.</p>
<p><span class="math display">\[\Omega_t = \left(X_{t-1}, X_{t-2}, ..., X_0 \right).\]</span></p>
<p>As we will this compact notation is quite useful.</p>
<div id="white-noise-processes" class="section level3">
<h3><span class="header-section-number">2.2.1</span> White noise processes</h3>
<p>The building block for most time series models is the Gaussian white noise process, which can be defined as</p>
<p><span class="math display">\[{W_t}\mathop \sim \limits^{iid} N\left( {0,\sigma _w^2} \right).\]</span></p>
<p>This definition implies that:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E[W_t | \Omega_t] = 0\)</span> for all <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(\operatorname{cov}\left(W_t, W_{t-h} \right) = \boldsymbol{1}_{h = 0} \; \sigma^2\)</span> for all <span class="math inline">\(t, h\)</span>.</li>
</ol>
<p>Therefore, this process present an absence of temporal (or serial) dependence and has a constant variance. This definition can be generalized in two sorts of processes, the <em>weak</em> and <em>strong</em> white noise. The process <span class="math inline">\((W_t)\)</span> is a weak white noise if</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E[W_t] = 0\)</span> for all <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(\operatorname{var}\left(W_t\right) = \sigma^2\)</span> for all <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(\operatorname{cov} \left(W_t, W_{t-h}\right) = 0\)</span>, for all <span class="math inline">\(t\)</span>, and for all <span class="math inline">\(h \neq 0\)</span>.</li>
</ol>
<p>Note that this definition does not imply that <span class="math inline">\(W_t\)</span> and <span class="math inline">\(W_{t-h}\)</span> are independent (for <span class="math inline">\(h \neq 0\)</span>) but simply uncorrelated. However, the notion of indepence is used to define a <em>strong</em> white noise as</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E[W_t] = 0\)</span> and <span class="math inline">\(\operatorname{var}(W_t) = \sigma^2 &lt; \infty\)</span>, for all <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(F(W_t) = F(W_{t-h})\)</span>, for all <span class="math inline">\(t,h\)</span> (where <span class="math inline">\(F(W_t)\)</span> denotes the distribution of <span class="math inline">\(W_t\)</span>),</li>
<li><span class="math inline">\(W_t\)</span> and <span class="math inline">\(W_{t-h}\)</span> are independent for all <span class="math inline">\(t\)</span> and for all <span class="math inline">\(h \neq 0\)</span>.</li>
</ol>
<p>It is clear from these definition that if a process is a strong white noise it is also a weak white noise. However, the converse is not true a shown in the following example:</p>
<p><strong>Example</strong>: Let <span class="math inline">\(X_t \mathop \sim \limits^{iid} F_t\)</span>, where <span class="math inline">\(F_t\)</span> denote a Student distribution with <span class="math inline">\(t\)</span> degrees of freedom. Such process is a weak but not a strong white noise.</p>
<p>The code below presents an example of how to simulate a Gaussian white noise process</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This code simulate a gaussian white noise process</span>
n =<span class="st"> </span><span class="dv">100</span>                               <span class="co"># process length</span>
sigma2 =<span class="st"> </span><span class="dv">1</span>                            <span class="co"># process variance</span>
Xt =<span class="st"> </span><span class="kw">gen.gts</span>(<span class="kw">WN</span>(<span class="dt">sigma2 =</span> <span class="dv">1</span>), <span class="dt">n =</span> n)
<span class="kw">plot</span>(Xt)</code></pre></div>
<p><img src="its_files/figure-html/example_WN-1.png" width="672" /></p>
<!--
white noise can actually be generalize

The process name of white noise has meaning in the notion of colors of noise. Specifically, the white noise is a process that mirrors white light's flat frequency spectrum. So, the process has equal frequencies in any interval of time.

*Definition:* **White Noise**

$w_t$ or $\varepsilon _t$ is a **white noise process** if $w_t$ are uncorrelated identically distributed random variables with
$E\left[w_t\right] = 0$ and $Var\left[w_t\right] = \sigma ^2$, for all $t$. We can represent this algebraically as:
$$y_t = w_t,$$
where ${w_t}\mathop \sim \limits^{id} WN\left( {0,\sigma _w^2} \right)$

Now, if the $w_t$ are **Normally (Gaussian) distributed**, then the process is known as a **Gaussian White Noise** e.g. ${w_t}\mathop \sim \limits^{iid} N\left( {0,{\sigma ^2}} \right)$ -->
<p>We 1.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="autocorrelation-and-stationarity.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/coatless/its/edit/master/01-intro.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
